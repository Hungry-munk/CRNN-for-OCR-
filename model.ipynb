{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Conv2D, MaxPooling2D, Dropout, Lambda\n",
    "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Reshape\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from configs import Configs \n",
    "from data_processing import data_preparator\n",
    "%run \"tester_functions.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Configs()\n",
    "batch_size = c.batch_size\n",
    "batch_size = 50\n",
    "image_size = c.form_height\n",
    "image_size = 128\n",
    "\n",
    "X, Y = data_preparator(c.image_paths, c.label_path, image_target_height = image_size, batch_size = batch_size, augmentation_probability = c.augmentation_probability )\n",
    "print(len(X))\n",
    "print(Y.shape)\n",
    "inpute_batch_displayer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Configs()\n",
    "# retrive precessed data that can be used for training \n",
    "X, Y = data_preparator(c.image_paths, c.label_path, image_target_height = c.image_height, image_target_width = c.image_width, batch_size = c.batch_size, augmentation_probability = c.augmentation_probability )\n",
    "\n",
    "# scramble arraies but keep corresponding indecies\n",
    "# Generate a random permutation of indices\n",
    "shuffled_indices = np.random.permutation(c.batch_size)\n",
    "\n",
    "# X = X[shuffled_indices]\n",
    "# Y = Y[shuffled_indices]\n",
    "# split data set into training, cross validation and test sets\n",
    "# training sets split \n",
    "train_split = int(0.75 * c.batch_size)\n",
    "X_train = X[:train_split]\n",
    "Y_train = Y[:train_split]\n",
    "# Cross validation sets\n",
    "CV_test_split = int(0.125 * c.batch_size)\n",
    "X_cv = X[train_split: train_split + CV_test_split]\n",
    "Y_cv = Y[train_split: train_split + CV_test_split]\n",
    "# testing sets\n",
    "X_test = X[train_split + CV_test_split:]\n",
    "Y_test = Y[train_split + CV_test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_for_rnn(x):\n",
    "    shape = K.int_shape(x)\n",
    "    return K.reshape(x, shape=(shape[0], -1, shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CRNN_model(input_shape, num_classes):\n",
    "    # TODO figure out input\n",
    "    inputs = Input(shape = input_shape)\n",
    "    # CNN\n",
    "    # CNN layers inspired by t he VGG architecture \n",
    "    inner = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(inputs)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(1, 2), name='max1')(inner) # pull size for maintaining vertical information\n",
    "\n",
    "    inner = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(1, 2), name='max2')(inner)\n",
    "\n",
    "    inner = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)  \n",
    "\n",
    "    inner = Conv2D(512, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(1, 2), name='max4')(inner)\n",
    "\n",
    "    # Dropout layer to help prevent overfitting\n",
    "    inner = Dropout(0.25)(inner)\n",
    "\n",
    "    # CNN to RNN transition\n",
    "    # use lambda layer and reshape function to create sequence \n",
    "    sequence = Lambda(reshape_for_rnn)(inner)\n",
    "\n",
    "    # RNN layers\n",
    "    # 2 sets of biderectional LSTM layers to allow for fruther and more nauiced learning \n",
    "    sequence = Bidirectional(LSTM(256, return_sequences=True))(inner) \n",
    "    sequence = Bidirectional(LSTM(256, return_sequences=True))(inner)\n",
    "    # final dense layer for character probabilities using softmax output\n",
    "    Dense(num_classes + 1, activation='softmax')(sequence)\n",
    "    # create model\n",
    "    model = Model(inputs = inputs, outputs = sequence)\n",
    "    \n",
    "    # return full model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
