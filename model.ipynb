{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Conv2D, MaxPooling2D, Dropout, Lambda\n",
    "from tensorflow.keras.layers import Input, Activation, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from configs import Configs \n",
    "from data_processing import create_datasets\n",
    "%run \"tester_functions.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all for GPU dynamic VRAM allocation \n",
    "K.clear_session()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_error_rate(y_true, y_pred):\n",
    "    # Assuming y_true and y_pred are already in index form, not one-hot encoded\n",
    "    y_true = K.get_value(y_true)\n",
    "    y_pred = K.get_value(y_pred)\n",
    "    \n",
    "    cer = []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        # Filter out the blank labels (typically 0 for CTC)\n",
    "        true_str = ''.join([chr(char) for char in true if char != 0])\n",
    "        pred_str = ''.join([chr(char) for char in pred if char != 0])\n",
    "        \n",
    "        # Calculate CER using Levenshtein distance\n",
    "        edit_distance = levenshtein_distance(true_str, pred_str)\n",
    "        cer.append(edit_distance / len(true_str) if len(true_str) > 0 else 0)\n",
    "\n",
    "    return np.mean(cer)\n",
    "\n",
    "def word_error_rate(y_true, y_pred):\n",
    "    # Assuming y_true and y_pred are already in index form, not one-hot encoded\n",
    "    y_true = K.get_value(y_pred)\n",
    "    y_pred = K.get_value(y_pred)\n",
    "    \n",
    "    wer = []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        # Decode the predictions and ground truths to strings\n",
    "        true_str = ''.join([chr(char) for char in true if char != 0])\n",
    "        pred_str = ''.join([chr(char) for char in pred if char != 0])\n",
    "        \n",
    "        # Split into words\n",
    "        true_words = true_str.split()\n",
    "        pred_words = pred_str.split()\n",
    "        \n",
    "        # Calculate WER using Levenshtein distance\n",
    "        edit_distance = levenshtein_distance(true_words, pred_words)\n",
    "        wer.append(edit_distance / len(true_words) if len(true_words) > 0 else 0)\n",
    "\n",
    "    return np.mean(wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTC loss function\n",
    "def ctc_loss_lambda_func(y_true, y_pred):\n",
    "    input_length = K.ones_like(y_pred[:, 0, 0]) * (K.int_shape(y_pred)[1])\n",
    "    label_length = K.sum(K.cast(K.not_equal(y_true, -1), 'int32'), axis=-1)\n",
    "    return K.ctc_batch_cost(y_true, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_map_to_seq(f_map):\n",
    "    # Get dynamic shape\n",
    "    shape = tf.shape(f_map)  # Use dynamic shape to handle None dimensions\n",
    "    batch_size, height, width, channels = shape[0], shape[1], shape[2], shape[3]\n",
    "    \n",
    "    # Reshape into (batch_size, timesteps, features)\n",
    "    sequence = tf.reshape(f_map, (batch_size, width, height * channels))\n",
    "    \n",
    "    return sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CRNN_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # CNN layers\n",
    "    f_maps = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(inputs)\n",
    "    f_maps = BatchNormalization()(f_maps)\n",
    "    f_maps = Activation('relu')(f_maps)\n",
    "    f_maps = MaxPooling2D(pool_size=(1, 2), name='max1')(f_maps) # maintain vertical information\n",
    "    \n",
    "    f_maps = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(f_maps)\n",
    "    f_maps = BatchNormalization()(f_maps)\n",
    "    f_maps = Activation('relu')(f_maps)\n",
    "    f_maps = MaxPooling2D(pool_size=(1, 2), name='max2')(f_maps)\n",
    "    \n",
    "    f_maps = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(f_maps)\n",
    "    f_maps = BatchNormalization()(f_maps)\n",
    "    f_maps = Activation('relu')(f_maps)\n",
    "    f_maps = MaxPooling2D(pool_size=(1, 2), name='max3')(f_maps)\n",
    "    \n",
    "    f_maps = Conv2D(512, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(f_maps)\n",
    "    f_maps = BatchNormalization()(f_maps)\n",
    "    f_maps = Activation('relu')(f_maps)\n",
    "    f_maps = MaxPooling2D(pool_size=(1, 2), name='max4')(f_maps)\n",
    "\n",
    "    # Dropout to help reduce overfitting\n",
    "    f_maps = Dropout(0.3)(f_maps)\n",
    "\n",
    "    # CNN to RNN transition: convert the feature maps into sequences\n",
    "    sequence = Lambda(f_map_to_seq)(f_maps)\n",
    "\n",
    "    # RNN layers (Bidirectional LSTMs)\n",
    "    sequence = Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='glorot_uniform'))(sequence)\n",
    "    sequence = Dropout(0.3)(sequence)\n",
    "    sequence = Bidirectional(LSTM(256, return_sequences=True, kernel_initializer='glorot_uniform'))(sequence)\n",
    "\n",
    "    # Dense layer with softmax activation for classification\n",
    "    outputs = Dense(num_classes, activation='softmax')(sequence)\n",
    "\n",
    "    # Create and return model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for creating tensorflow datasets to allow for variable images and ground truth labels\n",
    "c = Configs()\n",
    "# get complete dataset\n",
    "total_dataset = create_datasets(c.image_paths, c.label_path, c.batch_size, c.image_height, c.augmentation_probability, c.cv_add_data)\n",
    "# get indivdual batches\n",
    "training_datasets = total_dataset.map(lambda train, cv:train)\n",
    "cv_datasets = total_dataset.map(lambda train, cv: cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in model and get it ready for training\n",
    "model = build_CRNN_model((c.image_height, None, 1), c.num_classes)\n",
    "learn_rate = c.learning_rate\n",
    "# define the model optimizer, loss function and metrics we want to track\n",
    "model.compile(optimizer=Adam(learning_rate=learn_rate),\n",
    "              loss=ctc_loss_lambda_func,\n",
    "              metrics=['accuracy' , character_error_rate, word_error_rate])\n",
    "\n",
    "# Callbacks for selecting the best model and early stopping if more training does nothing \n",
    "checkpoint = ModelCheckpoint('OCR model', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs for training \n",
    "epochs = c.epoch_num \n",
    "epochs = 1\n",
    "model = model.fit(\n",
    "    training_datasets,\n",
    "    epochs=epochs,\n",
    "    validation_data=cv_datasets,\n",
    "    callbacks=[checkpoint, early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to be able to import later\n",
    "model.save('OCR model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
