{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***importing packages and libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import RandomBrightness, RandomContrast, RandomZoom\n",
    "import pathlib as pl\n",
    "import xml.etree.ElementTree as ET\n",
    "from configs import modelConfigs as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(image_path, target_height):\n",
    "    # Load image\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=1)  # Decode to grayscale\n",
    "    \n",
    "    # Convert image to float32 and normalize to [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "\n",
    "    # Convert to numpy array\n",
    "    h, w, _ = shape.numpy()\n",
    "\n",
    "    # Calculate new width based on target height\n",
    "    aspect_ratio = tf.cast(w, tf.float32) / tf.cast(h, tf.float32)\n",
    "    new_width = tf.cast(target_height * aspect_ratio, tf.int32)\n",
    "\n",
    "    # Resize image\n",
    "    image_resized = tf.image.resize(image, [target_height, new_width])\n",
    "\n",
    "    return image_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_augmentation_model():\n",
    "    augmentation_model = tf.keras.Sequential([\n",
    "        RandomBrightness(factor=(-0.1, 0.1), value_range=(0, 1)),\n",
    "        RandomContrast(factor=0.05),\n",
    "        RandomZoom(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2), fill_mode='constant', fill_value=1.0)     \n",
    "    ])\n",
    "    return augmentation_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for inspiration not for actual usage\n",
    "\"\"\"\n",
    "def input_batch_generator(image_paths, target_height, target_width, batch_size, augmentation_probability=0.2):\n",
    "    while True:\n",
    "        batch_images = []\n",
    "        for image_path in image_paths:\n",
    "            image = pre_process_image(image_path, target_height)\n",
    "            if np.random.rand() < augmentation_probability:\n",
    "                image = augment_image(image)\n",
    "            if image.shape[1] < target_width:\n",
    "                pad_width = target_width - image.shape[1]\n",
    "                image = np.pad(image, ((0, 0), (0, pad_width)), mode='constant', constant_values=1.0)\n",
    "            else:\n",
    "                image = image[:, :target_width]\n",
    "            batch_images.append(image)\n",
    "            if len(batch_images) == batch_size:\n",
    "                yield np.array(batch_images)\n",
    "                batch_images = []\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the 2 functions for retrive the necessary image file path for each folder\n",
    "\"\"\"\n",
    "brainstorm:\n",
    "batch generator...\n",
    "batch_generator loops through file paths and feeds that file path into a function that outputs\n",
    "a tuple with an image path and its associated XML path.\n",
    "\n",
    "segmenting the loops...\n",
    "have 2 seperate loops for each folder and varaibles to keep track of the \n",
    "final image that was passed into the training batch (to remember the final image placed in the batch).\n",
    "\n",
    "input and output retrieval for batch generation...\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparator(image_paths, batch_size, target_height, augmentation_probability = 0.3, batch_data_split = (0.4, 0.6)):\n",
    "    forms_ex = pl.Path(image_paths[0])\n",
    "    sentence_ex = pl.Path(image_paths[1])\n",
    "    #keep track of last image from the imageg data base \n",
    "    last_image_forms = 0\n",
    "    last_image_sentence = 0\n",
    "\n",
    "    forms_tot_num = round(batch_size * batch_data_split[0])\n",
    "    senetence_tot_num = round(batch_size * batch_data_split[1])\n",
    "    \n",
    "    augmentation_model = build_augmentation_model()\n",
    "\n",
    "    data = [] #initilaise ata array\n",
    "    \n",
    "    pos_counter = 0\n",
    "    for image_path in forms_ex.iterdir(): #loop thorugh the forms array\n",
    "        # split the batch by the percentage outlined\n",
    "        if pos_counter == last_image_forms + forms_tot_num + 1:\n",
    "            #number of forms added\n",
    "            break\n",
    "        elif pos_counter >= last_image_forms:\n",
    "            pos_counter += 1\n",
    "            #change the imagepath data structure from pathlib structures into string for image preporcessing\n",
    "            if not isinstance(image_path,str):\n",
    "                image_path = str(image_path)\n",
    "            image = pre_process_image(image_path, target_height)\n",
    "            #apply augementation based on probability\n",
    "            if np.random.rand() < augmentation_probability:\n",
    "                image = augmentation_model(image)\n",
    "            data.append(image)\n",
    "        \n",
    "    #for image_path in sentence_ex.iterdir():\n",
    "        \n",
    "    #convert batch array into numpy array to allow for model training  \n",
    "    return np.array(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparator_2(X_image_paths, Y_image_path , data_length =1000 , image_target_height = 512, augmentation_probability = 0.3, data_split = (0.4, 0.6)):\n",
    "    # directory containing labels for training data\n",
    "    label_dir = pl.Path(Y_image_path)\n",
    "    #forms and lines paths\n",
    "    forms_pat = X_image_paths[0]\n",
    "    lines_path = X_image_paths[1]\n",
    "    #training example and label data X and Y\n",
    "    X = []\n",
    "    Y = []\n",
    "    #keep track of how many files are being added to the data batch\n",
    "    counter = 0\n",
    "    for XML_path in label_dir.iterdir():\n",
    "        if counter == data_length:\n",
    "            break\n",
    "        counter += 1\n",
    "        \n",
    "\n",
    "\n",
    "    #return (np.array(X), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preparator_2(c().image_paths, c().label_path, 1 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
