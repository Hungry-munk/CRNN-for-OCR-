{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***importing packages and libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import RandomContrast, RandomZoom\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import pathlib as pl\n",
    "import xml.etree.ElementTree as ET\n",
    "from configs import Configs \n",
    "import os\n",
    "from html import unescape\n",
    "%run \"tester_functions.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(image, target_height, target_width):\n",
    "    # Load image\n",
    "    if isinstance(image, str):\n",
    "        # If image is a file path, read and decode it\n",
    "        image = tf.io.read_file(image)\n",
    "        image = tf.image.decode_image(image, channels=1)  # Decode to grayscale\n",
    "\n",
    "    # Resize image\n",
    "    image_resized = tf.image.resize_with_pad(image, target_height, target_width)\n",
    "\n",
    "    # Convert image to float32 and normalize to [0, 1]\n",
    "    n_image = tf.image.convert_image_dtype(image_resized, tf.float32)\n",
    "\n",
    "    return n_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to seperate the forms imges computer text written parts from the hand written parts\n",
    "# important as label would need to be doubled to train both parts and other training complications\n",
    "# the name portion is also needs to be removed as their is not training data on the text\n",
    "def forms_text_seporator(form_path, HW_bounding_box):\n",
    "    # read file in based on file path\n",
    "    image = tf.io.read_file(form_path)\n",
    "    image = tf.io.decode_image(image, channels=1) #decode image to grayscale\n",
    "    # configs for dimensions\n",
    "    configs = Configs()\n",
    "    # bouding box in the convention [y1, x1, y2, x2]\n",
    "    CW_bounding_box = [0, 0, HW_bounding_box[0] , configs.form_width ]\n",
    "    # crop original form image to just handwritten (hence HW) part using correct bounding box\n",
    "    HW_cropped_image = tf.image.crop_to_bounding_box(\n",
    "        image, \n",
    "        HW_bounding_box[0],\n",
    "        HW_bounding_box[1],\n",
    "        HW_bounding_box[2] - HW_bounding_box[0],\n",
    "        HW_bounding_box[3] - HW_bounding_box[1]\n",
    "    )\n",
    "    # crop original form image to just computer wirtten (hence CW) part using correct bounding box \n",
    "    CW_cropped_image = tf.image.crop_to_bounding_box(\n",
    "        image, \n",
    "        CW_bounding_box[0],\n",
    "        CW_bounding_box[1],\n",
    "        CW_bounding_box[2],\n",
    "        CW_bounding_box[3]\n",
    "    )\n",
    "    return HW_cropped_image, CW_cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_augmentation_model():\n",
    "    augmentation_model = tf.keras.Sequential([\n",
    "        RandomContrast(factor=0.5),\n",
    "        RandomZoom(height_factor=(-0.1, 0.1), width_factor=(-0.1, 0.1), fill_mode='constant', fill_value=1.0)     \n",
    "    ])\n",
    "    return augmentation_model\n",
    "\n",
    "def random_pad(image, max_padding):\n",
    "    if isinstance(image, str):\n",
    "        # If image is a file path, read and decode it\n",
    "        image = tf.io.read_file(image)\n",
    "        image = tf.image.decode_image(image, channels=1)\n",
    "        \n",
    "    elif isinstance(image, tf.Tensor):\n",
    "        # If it's a tensor, ensure it's 3D and uint8\n",
    "        if len(tf.shape(image)) == 4:\n",
    "            image = tf.squeeze(image, axis=0)  # Remove batch dimension if present\n",
    "        if image.dtype != tf.uint8:\n",
    "            image = tf.cast(tf.clip_by_value(image * 255, 0, 255), tf.uint8)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a tensor or a file path string\")\n",
    "\n",
    "    # Ensure image is a 3D tensor (height, width, channels)\n",
    "    if len(tf.shape(image)) == 2:\n",
    "        image = tf.expand_dims(image, -1)\n",
    "\n",
    "    # Generate random padding values\n",
    "    pad_top = tf.random.uniform([], minval=max_padding // 4, maxval=max_padding, dtype=tf.int32)\n",
    "    pad_bottom = tf.random.uniform([], minval=max_padding // 4, maxval=max_padding, dtype=tf.int32)\n",
    "    pad_left = tf.random.uniform([], minval=max_padding // 4, maxval=max_padding, dtype=tf.int32)\n",
    "    pad_right = tf.random.uniform([], minval=max_padding // 4, maxval=max_padding, dtype=tf.int32)\n",
    "    \n",
    "    # Create padding tensor to outline how to pad\n",
    "    paddings = [[pad_top, pad_bottom], [pad_left, pad_right], [0, 0]]\n",
    "    # Pad the image\n",
    "    padded_image = tf.pad(image, paddings, mode='CONSTANT',  constant_values=255)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "# randomly decide how much to pad form HW or CW images \n",
    "def form_pad_val_gen():\n",
    "    return tf.random.uniform([], minval=100, maxval=250, dtype=tf.int32)\n",
    "# randomly decide how much to pad line images\n",
    "def line_pad_val_gen():\n",
    "    return tf.random.uniform([], minval=20, maxval=70, dtype=tf.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function to update the form croping bouding box based on new data from new line\n",
    "def form_crop_bouding_box_updater(current_bounding_box, line, line_num, total_lin_num):\n",
    "    # current bounding box is the dimensions of the current word adjusted\n",
    "    words = line.findall('word')\n",
    "    for word in words:\n",
    "        chars = word.findall('cmp')\n",
    "        for char in chars:\n",
    "            # first x coord\n",
    "            x_val = int(char.get('x'))\n",
    "            if current_bounding_box[1] == 0:\n",
    "                current_bounding_box[1] = x_val\n",
    "            elif current_bounding_box[1] > x_val:\n",
    "                current_bounding_box[1] = x_val\n",
    "            #  second x coord \n",
    "            if current_bounding_box[3] < x_val:\n",
    "                current_bounding_box[3] = x_val\n",
    "            # handling y coords cases\n",
    "            y_val = int(char.get('y'))\n",
    "            if line_num == 0:\n",
    "                if current_bounding_box[0] == 0:\n",
    "                    current_bounding_box[0] = y_val\n",
    "                elif current_bounding_box[0] > y_val:\n",
    "                    current_bounding_box[0] = y_val\n",
    "            elif line_num == total_lin_num:\n",
    "                if current_bounding_box[2] == 0:\n",
    "                    current_bounding_box[2] = y_val\n",
    "                elif current_bounding_box[2] < y_val:\n",
    "                    current_bounding_box[2] = y_val\n",
    "    return current_bounding_box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO set appropriate defult image heights and width\n",
    "def data_preparator(X_image_paths, Y_image_path , data_length = 1000 , image_target_height = 512, image_target_width = 1024, augmentation_probability = 0.35):\n",
    "    # directory containing labels for training data\n",
    "    label_dir = pl.Path(Y_image_path)\n",
    "    # get configs\n",
    "    configs = Configs()\n",
    "    # forms and lines paths\n",
    "    forms_path = X_image_paths[0]\n",
    "    lines_path = X_image_paths[1]\n",
    "    # training example and label data X and Y\n",
    "    X = []\n",
    "    Y = []\n",
    "    # keep track of the number files are being added to the data batch\n",
    "    data_counter = 0\n",
    "    # keep track of length of longest sequence\n",
    "    longest_seq_len = 0\n",
    "    # data augmentor\n",
    "    augmentation_model = build_augmentation_model()\n",
    "\n",
    "    for XML_path in label_dir.iterdir():\n",
    "        if data_counter >= data_length:\n",
    "            break\n",
    "        # get XML root element \n",
    "        root = ET.parse(str(XML_path)).getroot()\n",
    "        # a lines in the XML file\n",
    "        all_line_ele = root.find('handwritten-part')\n",
    "        lines = all_line_ele.findall('line')\n",
    "        # get bounding boxes for handwritten part \n",
    "        # bouding box in the convention [y1, x1, y2, x2]\n",
    "        form_crop_bounding_box = [0] * 4\n",
    "        form_full_text = '' # will be added onto this string \n",
    "        line_counter = 0\n",
    "        line_nums = len(lines) - 1 # the number of lines\n",
    "        # sub foilder for form that contains the lines for that form\n",
    "        subf_path = root.get('id')\n",
    "\n",
    "        # for lines\n",
    "        for line in lines:\n",
    "            \n",
    "            line_text = line.get('text')\n",
    "            sequence = []\n",
    "            # remove HTML chars and replace with just their  correpsonding chars \n",
    "            line_text = unescape(line_text)\n",
    "            # create a sequence label int's for current line using mapped chars and line text \n",
    "            for char in line_text:\n",
    "                sequence.append(configs.char_to_index_map[char])\n",
    "    \n",
    "            # append to sequence data as a numpy array with data type of int32\n",
    "            Y.append(np.array(sequence, dtype=np.int32))\n",
    "\n",
    "            form_full_text += f' {line_text}'\n",
    "\n",
    "            # image path in the subfolder\n",
    "            image_subf_path = line.get('id')\n",
    "            # sulber folder name (is the first 3 chars)\n",
    "            subf_name = image_subf_path[:3]\n",
    "            \n",
    "            full_line_image_path = f'{lines_path}/{subf_name}/{subf_path}/{image_subf_path}.png'\n",
    "            #process the image \n",
    "            line_image = random_pad(full_line_image_path, line_pad_val_gen())\n",
    "            line_image = pre_process_image(line_image, image_target_height, image_target_width)\n",
    "            # randomly with a chosen probability augment\n",
    "            if np.random.rand() < augmentation_probability:\n",
    "                line_image = augmentation_model(line_image)\n",
    "                \n",
    "            X.append(line_image)\n",
    "            data_counter += 1\n",
    "            \n",
    "            form_crop_bounding_box = form_crop_bouding_box_updater(\n",
    "                form_crop_bounding_box,\n",
    "                line,\n",
    "                line_counter,\n",
    "                line_nums\n",
    "            )\n",
    "            line_counter += 1\n",
    "        \n",
    "        HW_sequence = []\n",
    "        CW_sequence = []\n",
    "        # add the extra text found in CW images\n",
    "        CW_extra_text = f'Sentence Database {subf_path}'\n",
    "        # create a sequence label int's for current line using mapped chars and line text\n",
    "        # for main text \n",
    "        for char in form_full_text:\n",
    "            HW_sequence.append(configs.char_to_index_map[char])\n",
    "\n",
    "        for char in CW_extra_text:\n",
    "            CW_sequence.append(configs.char_to_index_map[char])\n",
    "\n",
    "        # append to sequence data as a numpy array with data type of int32\n",
    "        np_sequence = np.array(HW_sequence, dtype=np.int32) \n",
    "        CW_np_extra_sequence = np.array(CW_sequence, dtype=np.int32)\n",
    "        # add sequences to sequence list Y\n",
    "        Y.append(np_sequence)\n",
    "        Y.append(np.concatenate((CW_np_extra_sequence, np_sequence)))\n",
    "        # form image path\n",
    "        full_form_image_path = f'{forms_path}/{subf_path}.png'\n",
    "        # crop the image in 2 parts and return images contain the HW and CW portions\n",
    "        CW_cropped_form_image, HW_cropped_form_image = forms_text_seporator(\n",
    "            full_form_image_path, \n",
    "            form_crop_bounding_box\n",
    "        )\n",
    "        # randomly pad all form image for richer training data\n",
    "        CW_form_image = random_pad(CW_cropped_form_image, form_pad_val_gen())\n",
    "        HW_form_image = random_pad(HW_cropped_form_image, form_pad_val_gen())\n",
    "\n",
    "        CW_form_image = pre_process_image(CW_form_image, image_target_height, image_target_width)\n",
    "        HW_form_image = pre_process_image(HW_form_image, image_target_height, image_target_width)\n",
    "\n",
    "        if np.random.rand() <= augmentation_probability:\n",
    "            CW_form_image = augmentation_model(CW_form_image)\n",
    "        if np.random.rand() <= augmentation_probability:\n",
    "            HW_form_image = augmentation_model(HW_form_image)\n",
    "            \n",
    "        X.append(HW_form_image)\n",
    "        X.append(CW_form_image)\n",
    "        \n",
    "        data_counter += 2\n",
    "    Y_padded = pad_sequences(Y, dtype='int32', padding = 'post', truncating='post') \n",
    "\n",
    "    return np.array(X[:data_length]), Y_padded[:data_length]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a01-000u\n",
      " A MOVE to stop Mr. Gaitskell from nominating any more Labour life Peers is to be made at a meeting of Labour M Ps tomorrow. Mr. Michael Foot has put down a resolution on the subject and he is to be backed by Mr. Will Griffiths, M P for Manchester Exchange.\n",
      "a01-000x\n",
      " A MOVE to stop Mr. Gaitskell from nominating any more Labour life Peers is to be made at a meeting of Labour 0M Ps tomorrow. Mr. Michael Foot has put down a resolution on the subject and he is to be backed by Mr. Will Griffiths, 0M P for Manchester Exchange.\n",
      "a01-003\n",
      " Though they may gather some Left-wing support, a large majority of Labour M Ps are likely to turn down the Foot-Griffiths resolution. Mr. Foot's line will be that as Labour M Ps opposed the Government Bill which brought life peers into existence, they should not now put forward nominees. He believes that the House of Lords should be abolished and that Labour should not take any steps which would appear to \"prop up\" an out-dated institution.\n",
      "a01-003u\n",
      " Though they may gather some Left-wing support, a large majority of Labour M Ps are likely to turn down the Foot- Griffiths resolution. Mr. Foot's line will be that as Labour M Ps opposed the Government Bill which brought life peers into existence, they should not now put forward nominees. He believes that the House of Lords should be abolished and that Labour should not take any steps which would appear to \"prop up\" an out-\n",
      "a01-003x\n",
      " Though they may gather some Left-wing support, a large majority of Labour 0M Ps are likely to turn down the Foot-Griffiths resolution. Mr. Foot's line will be that as Labour 0M Ps opposed the Govern- ment Bill which brought life peers into existence, they should not now put forward nominees. He believes that the House of Lords should be abolished and that Labour should not take any steps which would appear to \"prop up\" an out-dated institution.\n",
      "a01-007\n",
      " Since 1958, 13 Labour life Peers and Peeresses have been created. Most Labour sentiment would # still favour the abolition of the House of Lords, but while it remains Labour has to have an adequate number of members. THE two rival African Nationalist Parties of Northern Rhodesia have agreed to get together to face the challenge from Sir Roy Welensky, the Federal Premier.\n",
      "a01-007u\n",
      " Since 1958, 13 Labour life Peers and Peeresses have been created. Most Labour sentiment would still favour the abolition of the House of Lords, but while it remains Labour has to have an adequate number of members. THE two rival African Nationalist Parties of Northern Rhodesia have agreed to get together to face the challenge from Sir Roy Welensky, the Federal Premier.\n",
      "a01-007x\n",
      " Since 1958, 13 Labour life Peers and # Peeresses have been created. Most Labour sentiment would still favour the abolition of the House of Lords, but while it remains Labour has to have an adequate number of members. THE two rival African Nationalist Parties of Northern Rhodesia have agreed to get together to face the challenge from Sir Roy Welensky, the Federal Premier.\n",
      "a01-011\n",
      " Delegates from Mr. Kenneth Kaunda's United National Independence Party (280,000 members) and Mr. Harry Nkumbula's African National Congress (400,000) will meet in London today to discuss a common course of action. Sir Roy is violently opposed to Africans getting an elected majority in Northern Rhodesia, but the Colonial Secretary, Mr. Iain Macleod, is insisting on a policy of change.\n",
      "a01-011u\n",
      " Delegates from Mr. Kenneth Kaunda's United National Independence Party (280,000 members) and Mr. Harry Nkumbula's African National Congress (400,000) will meet in London today to discuss a common course of action. Sir Roy is violently opposed to Africans getting an elected majority in Northern Rhodesia, but the Colonial Secretary, Mr. Iain Macleod, is insisting on a policy of change.\n"
     ]
    }
   ],
   "source": [
    "configs = Configs()\n",
    "X, Y = data_preparator(configs.image_paths, configs.label_path, data_length = 100, augmentation_probability=0.4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpute_batch_displayer(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
