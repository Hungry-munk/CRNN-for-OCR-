{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***importing packages and libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nonly run if first time to install pacakges\\n!pip install numpy\\n!pip install tensorflow\\n!pip install pathlib\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "only run if first time to install pacakges\n",
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install pathlib\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import RandomBrightness, RandomContrast, RandomZoom\n",
    "from configs import modelConfigs\n",
    "import pathlib as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(image_path, target_height):\n",
    "    # Load image\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=1)  # Decode to grayscale\n",
    "    \n",
    "    # Convert image to float32 and normalize to [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "\n",
    "    # Convert to numpy array\n",
    "    h, w, _ = shape.numpy()\n",
    "\n",
    "    # Calculate new width based on target height\n",
    "    aspect_ratio = tf.cast(w, tf.float32) / tf.cast(h, tf.float32)\n",
    "    new_width = tf.cast(target_height * aspect_ratio, tf.int32)\n",
    "\n",
    "    # Resize image\n",
    "    image_resized = tf.image.resize(image, [target_height, new_width])\n",
    "\n",
    "    return image_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_augmentation_model():\n",
    "    augmentation_model = tf.keras.Sequential([\n",
    "        RandomBrightness(factor=(-0.05, 0.05), value_range=(0, 1)),\n",
    "        RandomContrast(factor=0.05),\n",
    "        RandomZoom(height_factor=(-0.02, 0.02), width_factor=(-0.02, 0.02), fill_mode='constant', fill_value=1.0)\n",
    "        \n",
    "    ])\n",
    "    return augmentation_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef input_batch_generator(image_paths, target_height, target_width, batch_size, augmentation_probability=0.2):\\n    while True:\\n        batch_images = []\\n        for image_path in image_paths:\\n            image = pre_process_image(image_path, target_height)\\n            if np.random.rand() < augmentation_probability:\\n                image = augment_image(image)\\n            if image.shape[1] < target_width:\\n                pad_width = target_width - image.shape[1]\\n                image = np.pad(image, ((0, 0), (0, pad_width)), mode='constant', constant_values=1.0)\\n            else:\\n                image = image[:, :target_width]\\n            batch_images.append(image)\\n            if len(batch_images) == batch_size:\\n                yield np.array(batch_images)\\n                batch_images = []\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function for inspiration not for actual usage\n",
    "\"\"\"\n",
    "def input_batch_generator(image_paths, target_height, target_width, batch_size, augmentation_probability=0.2):\n",
    "    while True:\n",
    "        batch_images = []\n",
    "        for image_path in image_paths:\n",
    "            image = pre_process_image(image_path, target_height)\n",
    "            if np.random.rand() < augmentation_probability:\n",
    "                image = augment_image(image)\n",
    "            if image.shape[1] < target_width:\n",
    "                pad_width = target_width - image.shape[1]\n",
    "                image = np.pad(image, ((0, 0), (0, pad_width)), mode='constant', constant_values=1.0)\n",
    "            else:\n",
    "                image = image[:, :target_width]\n",
    "            batch_images.append(image)\n",
    "            if len(batch_images) == batch_size:\n",
    "                yield np.array(batch_images)\n",
    "                batch_images = []\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbrainstorm:\\nbatch generator...\\nbatch_generator loops through file paths and feeds that file path into a function that outputs\\na tuple with an image path and its associated XML path.\\n\\nsegmenting the loops...\\nhave 2 seperate loops for each folder and varaibles to keep track of the \\nfinal image that was passed into the training batch (to remember the final image placed in the batch).\\n\\ninput and output retrieval for batch generation...\\n\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the 2 functions for retrive the necessary image file path for each folder\n",
    "\"\"\"\n",
    "brainstorm:\n",
    "batch generator...\n",
    "batch_generator loops through file paths and feeds that file path into a function that outputs\n",
    "a tuple with an image path and its associated XML path.\n",
    "\n",
    "segmenting the loops...\n",
    "have 2 seperate loops for each folder and varaibles to keep track of the \n",
    "final image that was passed into the training batch (to remember the final image placed in the batch).\n",
    "\n",
    "input and output retrieval for batch generation...\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def batch_generator(image_paths , batch_size, target_height, augmentation_probability = 0.2, batch_data_split = (0.4, 0.6)):\n",
    "    forms_ex = pl.Path(image_paths[0])\n",
    "    sentence_ex = pl.Path(image_paths[1])\n",
    "    #keep track of last image from the imageg data base \n",
    "    last_image_forms = 0\n",
    "    last_image_sentence = 0\n",
    "\n",
    "    forms_tot_num = round(batch_size * batch_data_split[0])\n",
    "    senetence_tot_num = round(batch_size * batch_data_split[1])\n",
    "    \n",
    "    while True:\n",
    "        batch = [] #initilaise batch array\n",
    "        \n",
    "        pos_counter = 0\n",
    "        for image_path in forms_ex.iterdir(): #loop thorugh the forms array\n",
    "            # split the batch by the percentage outlined\n",
    "            if pos_counter == last_image_forms + forms_tot_num + 1:\n",
    "                #number of forms added\n",
    "                break\n",
    "            elif pos_counter >= last_image_forms:\n",
    "                pos_counter += 1\n",
    "                #change the posixPath data structure into string for image preporcessing\n",
    "                if isinstance(image_path, pl.PosixPath):\n",
    "                    image_path = str(image_path)\n",
    "                image = pre_process_image(image_path, target_height)\n",
    "                batch.append(image)\n",
    "        break\n",
    "    \n",
    "    return np.array(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:307\u001b[0m, in \u001b[0;36m_EagerTensorBase.__float__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__float__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m--> 307\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m      4\u001b[0m c \u001b[38;5;241m=\u001b[39m modelConfigs()\n\u001b[0;32m----> 6\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugmentation_probability\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_split\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch)\n",
      "Cell \u001b[0;32mIn[17], line 26\u001b[0m, in \u001b[0;36mbatch_generator\u001b[0;34m(image_paths, batch_size, target_height, augmentation_probability, batch_data_split)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(image_path)\n\u001b[1;32m     25\u001b[0m             image \u001b[38;5;241m=\u001b[39m pre_process_image(image_path, target_height)\n\u001b[0;32m---> 26\u001b[0m             \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpos_counter\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m image\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from configs import modelConfigs \n",
    "import pathlib as pl\n",
    "\n",
    "c = modelConfigs()\n",
    "\n",
    "batch = batch_generator(c.image_paths, c.batch_size, c.image_height, c.augmentation_probability, c.data_split)\n",
    "print(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
